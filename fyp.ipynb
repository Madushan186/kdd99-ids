{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b2ca54-f131-4dd6-aede-7ad56998cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting ultimate data load fix: Skipping first row and using regex separator...\n",
      "WARNING: Unexpected column count: 1. Expected 42. Proceeding...\n",
      "DataFrame successfully loaded with 1 columns.\n",
      "Applying One-Hot Encoding to categorical features...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([1, 2, 3], dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m categorical_cols = [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m] \n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mApplying One-Hot Encoding to categorical features...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m X_processed = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Ensure data types are numeric and handle any potential infinity/NaN introduced\u001b[39;00m\n\u001b[32m     51\u001b[39m X_processed = X_processed.replace([\u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m), -\u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)], \u001b[32m0\u001b[39m).fillna(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/reshape/encoding.py:170\u001b[39m, in \u001b[36mget_dummies\u001b[39m\u001b[34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[39m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput must be a list-like for parameter `columns`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     data_to_encode = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index([1, 2, 3], dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define the file path\n",
    "DATA_FILE = 'data/kddcup.data_10_percent' \n",
    "\n",
    "print(\"Attempting ultimate data load fix: Skipping first row and using regex separator...\")\n",
    "\n",
    "# --- Load the Data using the Regex Separator and Skip Rows ---\n",
    "# We use the Python engine (slower) because it's the only one that handles regex separators.\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        DATA_FILE, \n",
    "        header=None, \n",
    "        sep=r'\\s+',               # Use regex to match one or more spaces as the separator (recommended fix)\n",
    "        engine='python',          # Must use the Python engine for regex separators\n",
    "        skiprows=1,               # CRITICAL FIX: Skip the very first row\n",
    "        skipinitialspace=True     \n",
    "    ) \n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR during data read: {e}\")\n",
    "    # You should not reach this point.\n",
    "\n",
    "# --- CRITICAL FIX: Handle the Trailing Label Column ---\n",
    "# Standard KDD data should have 42 columns (41 features + 1 label).\n",
    "if df.shape[1] == 43:\n",
    "    print(\"Detected 43 columns; dropping the empty trailing column.\")\n",
    "    df = df.iloc[:, :-1]\n",
    "elif df.shape[1] != 42:\n",
    "    print(f\"WARNING: Unexpected column count: {df.shape[1]}. Expected 42. Proceeding...\")\n",
    "    \n",
    "print(f\"DataFrame successfully loaded with {df.shape[1]} columns.\")\n",
    "\n",
    "# --- 1. Separate Features (X) and Label (y) ---\n",
    "X = df.iloc[:, :-1]   # Features (index 0 to 40)\n",
    "y = df.iloc[:, -1]    # Label (index 41)\n",
    "\n",
    "# --- 2. Label Binarization (Attack vs. Normal) ---\n",
    "y = y.apply(lambda x: 0 if x.strip().strip('.') == 'normal' else 1)\n",
    "\n",
    "# --- 3. One-Hot Encoding for Categorical Features ---\n",
    "categorical_cols = [1, 2, 3] \n",
    "\n",
    "print(\"Applying One-Hot Encoding to categorical features...\")\n",
    "X_processed = pd.get_dummies(X, columns=categorical_cols) \n",
    "\n",
    "# Ensure data types are numeric and handle any potential infinity/NaN introduced\n",
    "X_processed = X_processed.replace([float('inf'), -float('inf')], 0).fillna(0)\n",
    "\n",
    "print(f\"New feature vector shape (features): {X_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44deb3f9-4d76-48f7-bd07-55e93d9211e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (125973, 43)\n",
      "   0    1         2   3    4     5   6   7   8   9   ...    33    34    35  \\\n",
      "0   0  tcp  ftp_data  SF  491     0   0   0   0   0  ...  0.17  0.03  0.17   \n",
      "1   0  udp     other  SF  146     0   0   0   0   0  ...  0.00  0.60  0.88   \n",
      "2   0  tcp   private  S0    0     0   0   0   0   0  ...  0.10  0.05  0.00   \n",
      "3   0  tcp      http  SF  232  8153   0   0   0   0  ...  1.00  0.00  0.03   \n",
      "4   0  tcp      http  SF  199   420   0   0   0   0  ...  1.00  0.00  0.00   \n",
      "\n",
      "     36    37    38    39    40       41  42  \n",
      "0  0.00  0.00  0.00  0.05  0.00   normal  20  \n",
      "1  0.00  0.00  0.00  0.00  0.00   normal  15  \n",
      "2  0.00  1.00  1.00  0.00  0.00  neptune  19  \n",
      "3  0.04  0.03  0.01  0.00  0.01   normal  21  \n",
      "4  0.00  0.00  0.00  0.00  0.00   normal  21  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "After dropping difficulty column: (125973, 42)\n",
      "Processed features shape: (125973, 122)\n",
      "Ready to train your model!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct file path\n",
    "DATA_FILE = \"/Users/lakshithamadushan/IDS project FYP/data/kddcup.data_10_percent\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_FILE, header=None)\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Drop the last column if it's the difficulty score\n",
    "if df.shape[1] == 43:\n",
    "    df = df.iloc[:, :-1]\n",
    "\n",
    "print(\"After dropping difficulty column:\", df.shape)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Binary classification: 0 = normal, 1 = attack\n",
    "y = y.apply(lambda x: 0 if x.strip().strip('.') == 'normal' else 1)\n",
    "\n",
    "# One-Hot Encoding for categorical columns: protocol_type, service, flag\n",
    "categorical_cols = [1, 2, 3]\n",
    "X_processed = pd.get_dummies(X, columns=categorical_cols)\n",
    "\n",
    "# Ensure no NaNs or infinity\n",
    "X_processed = X_processed.fillna(0)\n",
    "\n",
    "print(\"Processed features shape:\", X_processed.shape)\n",
    "print(\"Ready to train your model!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "388d932b-cbaf-4c47-9ca4-84f7e8c3f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training (80%) and testing (20%)...\n",
      "Starting Model Training (Random Forest Classifier)... This may take a few minutes.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# n_jobs=-1 tells the model to use all CPU cores on your MacBook Pro\u001b[39;00m\n\u001b[32m     16\u001b[39m model = RandomForestClassifier(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m) \n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# --- 6. Evaluate and Save ---\u001b[39;00m\n\u001b[32m     20\u001b[39m accuracy = model.score(X_test, y_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:359\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[32m    372\u001b[39m estimator = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimator)(criterion=\u001b[38;5;28mself\u001b[39m.criterion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2929\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2846\u001b[39m     _estimator,\n\u001b[32m   2847\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2853\u001b[39m     **check_params,\n\u001b[32m   2854\u001b[39m ):\n\u001b[32m   2855\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2856\u001b[39m \n\u001b[32m   2857\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2927\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2928\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2929\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2930\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2725\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2698\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Set or check the `feature_names_in_` attribute of an estimator.\u001b[39;00m\n\u001b[32m   2699\u001b[39m \n\u001b[32m   2700\u001b[39m \u001b[33;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2721\u001b[39m \u001b[33;03m       should set `reset=False`.\u001b[39;00m\n\u001b[32m   2722\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2724\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[32m-> \u001b[39m\u001b[32m2725\u001b[39m     feature_names_in = \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2726\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2727\u001b[39m         estimator.feature_names_in_ = feature_names_in\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2427\u001b[39m, in \u001b[36m_get_feature_names\u001b[39m\u001b[34m(X)\u001b[39m\n\u001b[32m   2425\u001b[39m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[32m   2426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[32m-> \u001b[39m\u001b[32m2427\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   2428\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFeature names are only supported if all input features have string names, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2429\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as feature name / column name types. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2430\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2431\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2432\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2433\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdata, or convert them all to a non-string data type.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2434\u001b[39m     )\n\u001b[32m   2436\u001b[39m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[32m   2437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[32m0\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "# Assuming X_processed and y are defined from the successful run above\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# --- 4. Split Data ---\n",
    "print(\"Splitting data into training (80%) and testing (20%)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- 5. Train Model ---\n",
    "print(\"Starting Model Training (Random Forest Classifier)... This may take a few minutes.\")\n",
    "# n_jobs=-1 tells the model to use all CPU cores on your MacBook Pro\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Evaluate and Save ---\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"\\nModel Accuracy on Test Data: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Aim for 98%+ accuracy!\n",
    "\n",
    "# Save the trained model and the feature list for the dashboard\n",
    "MODEL_FILE = 'basic_model.pkl'\n",
    "FEATURE_FILE = 'feature_columns.pkl'\n",
    "\n",
    "with open(MODEL_FILE, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    \n",
    "with open(FEATURE_FILE, 'wb') as f:\n",
    "    pickle.dump(X_processed.columns.tolist(), f)\n",
    "    \n",
    "print(f\"\\nSuccessfully saved model to: {MODEL_FILE}\")\n",
    "print(f\"Successfully saved feature list to: {FEATURE_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c2ed81d-a71b-4f23-b78b-3a303181d3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (100778, 122) Test set: (25195, 122)\n",
      "Training the Random Forest model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 3️⃣ Train the model\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining the Random Forest model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mrf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel training complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 4️⃣ Predict on the test set\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:359\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[32m    372\u001b[39m estimator = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimator)(criterion=\u001b[38;5;28mself\u001b[39m.criterion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2929\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2846\u001b[39m     _estimator,\n\u001b[32m   2847\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2853\u001b[39m     **check_params,\n\u001b[32m   2854\u001b[39m ):\n\u001b[32m   2855\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2856\u001b[39m \n\u001b[32m   2857\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2927\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2928\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2929\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2930\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2725\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2698\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Set or check the `feature_names_in_` attribute of an estimator.\u001b[39;00m\n\u001b[32m   2699\u001b[39m \n\u001b[32m   2700\u001b[39m \u001b[33;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2721\u001b[39m \u001b[33;03m       should set `reset=False`.\u001b[39;00m\n\u001b[32m   2722\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2724\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[32m-> \u001b[39m\u001b[32m2725\u001b[39m     feature_names_in = \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2726\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2727\u001b[39m         estimator.feature_names_in_ = feature_names_in\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2427\u001b[39m, in \u001b[36m_get_feature_names\u001b[39m\u001b[34m(X)\u001b[39m\n\u001b[32m   2425\u001b[39m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[32m   2426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[32m-> \u001b[39m\u001b[32m2427\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   2428\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFeature names are only supported if all input features have string names, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2429\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as feature name / column name types. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2430\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2431\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2432\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2433\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdata, or convert them all to a non-string data type.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2434\u001b[39m     )\n\u001b[32m   2436\u001b[39m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[32m   2437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[32m0\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "\n",
    "# 1️⃣ Split the dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set:\", X_train.shape, \"Test set:\", X_test.shape)\n",
    "\n",
    "# 2️⃣ Initialize Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,    # number of trees\n",
    "    random_state=42,\n",
    "    n_jobs=-1            # use all cores for faster training\n",
    ")\n",
    "\n",
    "# 3️⃣ Train the model\n",
    "print(\"Training the Random Forest model...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# 4️⃣ Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 5️⃣ Evaluate accuracy and performance\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 6️⃣ Save the trained model for later use\n",
    "MODEL_FILE = \"rf_model.pkl\"\n",
    "with open(MODEL_FILE, \"wb\") as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "print(f\"Trained model saved as '{MODEL_FILE}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5987ea86-2d0d-4aae-af6e-f8fc7ecbb2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Training complete!\n",
      "Accuracy: 99.88%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13422\n",
      "           1       1.00      1.00      1.00     11773\n",
      "\n",
      "    accuracy                           1.00     25195\n",
      "   macro avg       1.00      1.00      1.00     25195\n",
      "weighted avg       1.00      1.00      1.00     25195\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13417     5]\n",
      " [   24 11749]]\n",
      "Model saved as rf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "# 1️⃣ Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2️⃣ Fix column types for scikit-learn\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "\n",
    "# 3️⃣ Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 4️⃣ Train\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# 5️⃣ Predict & Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 6️⃣ Save model\n",
    "with open(\"rf_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "print(\"Model saved as rf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91484da2-8fda-43a1-b335-9c010144a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attack(new_data):\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "\n",
    "    # Load the model\n",
    "    with open(\"rf_model.pkl\", \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # Ensure categorical columns are one-hot encoded\n",
    "    new_data_processed = pd.get_dummies(new_data)\n",
    "    \n",
    "    # Align columns with training data\n",
    "    model_features = model.feature_names_in_\n",
    "    for col in model_features:\n",
    "        if col not in new_data_processed:\n",
    "            new_data_processed[col] = 0\n",
    "    new_data_processed = new_data_processed[model_features]\n",
    "    \n",
    "    return model.predict(new_data_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58932d83-f213-42bc-95fc-93ea726a45e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
